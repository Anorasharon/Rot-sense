{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "521e08e1-b811-42d1-8482-0226d7cbc09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/ultralytics/yolov5.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec5db488-0970-4076-b950-8e4c489db700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\deep learning\\rotsense\\yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d3b2d05-4068-4ca3-9947-2b4476248d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt\n",
    "#!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63966ae5-437c-4cd3-9b3d-153170cf699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afb21e02-c11e-4dba-be04-81c165c01913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\deep learning\\rotsense\\yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd \"D:/deep learning/rotsense/yolov5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "368bef8e-5b10-4ece-aacd-32e8e0428eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Path to YOLOv5 clone directory\n",
    "yolo_path = r\"D:\\deep learning\\rotsense\\yolov5\"\n",
    "os.chdir(yolo_path)\n",
    "\n",
    "# Add YOLOv5 to system path\n",
    "if yolo_path not in sys.path:\n",
    "    sys.path.append(yolo_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f6d8eef-3465-445c-90e7-c8534654c9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.augmentations import letterbox\n",
    "from utils.general import non_max_suppression\n",
    "from utils.torch_utils import select_device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96cb0167-7ed2-43a1-bc54-41e369b454e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "yolo_path = r\"D:\\deep learning\\rotsense\\yolov5\"\n",
    "os.chdir(yolo_path)\n",
    "if yolo_path not in sys.path:\n",
    "    sys.path.append(yolo_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a2cb4c8-7ebb-4cbd-acc5-667567481f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pickle\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7695aed-cc7e-4ef6-9f43-5a9f717be460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2025-7-8 Python-3.10.18 torch-2.7.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7088338 parameters, 0 gradients, 16.0 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "# Use CPU or GPU if available\n",
    "device = select_device('')  # '' = auto\n",
    "\n",
    "weights_path = r\"D:\\deep learning\\rotsense\\yolov5\\best.pt\"\n",
    " \n",
    "\n",
    "# Initialize model\n",
    "model = DetectMultiBackend(weights_path, device=device)\n",
    "stride = model.stride\n",
    "\n",
    "names = model.names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57ad8878-f99b-446e-ab50-430b25fb4d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import torch\\nimport cv2\\n\\n# Load trained YOLOv5 model\\nmodel = torch.hub.load('ultralytics/yolov5', 'custom', path='best.pt', force_reload=True)\\n\\n# Start webcam\\ncap = cv2.VideoCapture(0)\\n\\nwhile cap.isOpened():\\n    ret, frame = cap.read()\\n    if not ret:\\n        break\\n\\n    # Inference\\n    results = model(frame)\\n    annotated = results.render()[0]\\n\\n    # Show output\\n    cv2.imshow('RotSense - Live Detection', annotated)\\n\\n    if cv2.waitKey(1) & 0xFF == ord('q'):\\n        break\\n\\ncap.release()\\ncv2.destroyAllWindows()\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import torch\n",
    "import cv2\n",
    "\n",
    "# Load trained YOLOv5 model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='best.pt', force_reload=True)\n",
    "\n",
    "# Start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Inference\n",
    "    results = model(frame)\n",
    "    annotated = results.render()[0]\n",
    "\n",
    "    # Show output\n",
    "    cv2.imshow('RotSense - Live Detection', annotated)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6f713cb-53c3-4a7c-a444-9a6797d913a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pickle\n",
    "class PosixPathUnpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == \"pathlib\" and name == \"PosixPath\":\n",
    "            return pathlib.WindowsPath\n",
    "        return super().find_class(module, name)\n",
    "\n",
    "def torch_load_patch(file_path, map_location=None):\n",
    "    import torch\n",
    "    with open(file_path, 'rb') as f:\n",
    "        unpickler = PosixPathUnpickler(f)\n",
    "        obj = unpickler.load()\n",
    "    return obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a47e7727-a412-4f0a-b4cd-e7a452ecab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_coords(img1_shape, coords, img0_shape, ratio_pad=None):\n",
    "\n",
    "    if ratio_pad is None: \n",
    "        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])\n",
    "        pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2  \n",
    "    else:\n",
    "        gain = ratio_pad[0][0]\n",
    "        pad = ratio_pad[1]\n",
    "\n",
    "    coords[:, [0, 2]] -= pad[0]  \n",
    "    coords[:, [1, 3]] -= pad[1] \n",
    "    coords[:, :4] /= gain\n",
    "    coords[:, 0].clamp_(0, img0_shape[1])  \n",
    "    coords[:, 1].clamp_(0, img0_shape[0])  \n",
    "    coords[:, 2].clamp_(0, img0_shape[1])  \n",
    "    coords[:, 3].clamp_(0, img0_shape[0]) \n",
    "    return coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "106ecf6c-18ca-4e2e-ad58-af19f68f08f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2025-7-8 Python-3.10.18 torch-2.7.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7088338 parameters, 0 gradients, 16.0 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of video.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pathlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.augmentations import letterbox\n",
    "from utils.general import non_max_suppression\n",
    "from utils.torch_utils import select_device\n",
    "\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "\n",
    "weights_path = r\"D:\\deep learning\\rotsense\\yolov5\\best.pt\"\n",
    "device = select_device('cpu')\n",
    "model = DetectMultiBackend(weights_path, device=device)\n",
    "model.eval()\n",
    "\n",
    "stride = model.stride\n",
    "names = model.names\n",
    "\n",
    "video_path = r\"D:\\deep learning\\rotsense\\rotsense video.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "\n",
    "display_width = 960\n",
    "display_height = 540\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video.\")\n",
    "        break\n",
    "\n",
    "    img = letterbox(frame, stride=stride, auto=False)[0]\n",
    "    img = img.transpose((2, 0, 1))[::-1]  # BGR to RGB\n",
    "    img = np.ascontiguousarray(img)\n",
    "    img = torch.from_numpy(img).to(device)\n",
    "    img = img.float() / 255.0\n",
    "    if img.ndimension() == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = model(img)\n",
    "        pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45)\n",
    "\n",
    " \n",
    "    for det in pred:\n",
    "        if len(det):\n",
    "            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], frame.shape).round()\n",
    "            for *xyxy, conf, cls in reversed(det):\n",
    "                label = f'{names[int(cls)]} {conf:.2f}'\n",
    "                cv2.rectangle(frame, (int(xyxy[0]), int(xyxy[1])), (int(xyxy[2]), int(xyxy[3])), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, label, (int(xyxy[0]), int(xyxy[1]) - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    resized_frame = cv2.resize(frame, (display_width, display_height))\n",
    "    cv2.imshow('RotSense - Video Detection', resized_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d89b7ca-e9fe-478d-ad9a-0ec9aba42cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
